{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53fe61",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (854577940.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31336/854577940.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install insightface opencv-python numpy\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install insightface opencv-python numpy\n",
    "pip install onnxruntime\n",
    "# pip install onnxruntime-gpu for gpu\n",
    "sudo apt update\n",
    "sudo apt install build-essential\n",
    "sudo apt install python3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt update\n",
    "sudo apt install libgtk2.0-dev pkg-config\n",
    "pip uninstall opencv-python opencv-contrib-python -y\n",
    "pip install opencv-python opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e2e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d5c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Face capture completed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# Configuration\n",
    "# ======================\n",
    "USER_NAME = \"user1\"         # change per user\n",
    "SAVE_DIR = \"dataset\"\n",
    "TOTAL_PER_POSE = 5\n",
    "poses = [\"front\", \"left\", \"right\"]\n",
    "\n",
    "# Create directories for each pose\n",
    "for pose in poses:\n",
    "    os.makedirs(os.path.join(SAVE_DIR, USER_NAME, pose), exist_ok=True)\n",
    "\n",
    "# Load Haarcascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# ======================\n",
    "# Countdown function\n",
    "# ======================\n",
    "def countdown(cap):\n",
    "    for i in range(3, 0, -1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        cv2.putText(frame, str(i), (260, 250),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 0, 255), 4)\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "# ======================\n",
    "# Draw face borders function\n",
    "# ======================\n",
    "def draw_face_borders(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 0), 3)  # black border\n",
    "    return frame, faces\n",
    "\n",
    "# ======================\n",
    "# Wait for 'S' function\n",
    "# ======================\n",
    "def wait_for_s(cap, message):\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Draw face border in live preview\n",
    "        frame, _ = draw_face_borders(frame)\n",
    "\n",
    "        cv2.putText(frame, message, (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press S to start | Q to quit\", (50, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('s'):\n",
    "            return True\n",
    "        elif key == ord('q'):\n",
    "            return False\n",
    "\n",
    "# ======================\n",
    "# Initialize camera\n",
    "# ======================\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for pose in poses:\n",
    "\n",
    "    ok = wait_for_s(cap, f\"Ready for {pose.upper()} pose\")\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    countdown(cap)\n",
    "\n",
    "    saved = 0\n",
    "    while saved < TOTAL_PER_POSE:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Draw face border\n",
    "        frame, faces = draw_face_borders(frame)\n",
    "\n",
    "        # Instruction overlay\n",
    "        cv2.putText(frame, f\"{pose.upper()} {saved}/{TOTAL_PER_POSE}\", (30, 450),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            # Show message and stop pose capture\n",
    "            cv2.putText(frame, \"No face detected! Move to correct position.\", (50, 200),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Capture\", frame)\n",
    "            cv2.waitKey(1500)  # pause to show message\n",
    "            print(f\"No face detected for {pose.upper()}, stopping this pose.\")\n",
    "            break\n",
    "\n",
    "        # If face detected, crop and save\n",
    "        (x, y, w, h) = faces[0]  # take first detected face\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        filename = os.path.join(SAVE_DIR, USER_NAME, pose, f\"{saved+1}.jpg\")\n",
    "        cv2.imwrite(filename, face_img)\n",
    "        saved += 1\n",
    "\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "        # small delay between captures\n",
    "        if cv2.waitKey(400) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "\n",
    "print(\"✅ Face capture completed!\")\n",
    "\n",
    "# ======================\n",
    "# Finish screen\n",
    "# ======================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    cv2.putText(frame, \"Capture Successful!\", (150, 200),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "    cv2.putText(frame, \"Press Q to Quit\", (180, 260),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8be8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Captured FRONT embedding 1/5\n",
      "Captured FRONT embedding 2/5\n",
      "Captured FRONT embedding 3/5\n",
      "Captured FRONT embedding 4/5\n",
      "Captured FRONT embedding 5/5\n",
      "Captured LEFT embedding 1/5\n",
      "Captured LEFT embedding 2/5\n",
      "Captured LEFT embedding 3/5\n",
      "Captured LEFT embedding 4/5\n",
      "Captured LEFT embedding 5/5\n",
      "Captured RIGHT embedding 1/5\n",
      "Captured RIGHT embedding 2/5\n",
      "Captured RIGHT embedding 3/5\n",
      "Captured RIGHT embedding 4/5\n",
      "Captured RIGHT embedding 5/5\n",
      "✅ Face embedding capture completed!\n",
      "✅ Combined embedding saved to embeddings/user1_embedding.npy\n",
      "   Total embeddings captured: 15\n",
      "   Embedding shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USER_NAME = \"user1\"  # change per user\n",
    "SAVE_DIR = \"embeddings\"\n",
    "OUTPUT_FILE = os.path.join(SAVE_DIR, f\"{USER_NAME}_embedding.npy\")\n",
    "TOTAL_PER_POSE = 5\n",
    "poses = [\"front\", \"left\", \"right\"]\n",
    "\n",
    "# Create directories for storing embeddings\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Load Haarcascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Initialize InsightFace for embedding extraction\n",
    "app = FaceAnalysis(name=\"buffalo_l\")  # MobileFaceNet ArcFace\n",
    "app.prepare(ctx_id=-1)  # CPU: -1, GPU: 0\n",
    "\n",
    "# Store all embeddings (across all poses)\n",
    "all_embeddings = []\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Countdown function\n",
    "# ======================\n",
    "def countdown(cap):\n",
    "    for i in range(3, 0, -1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        cv2.putText(\n",
    "            frame, str(i), (260, 250), cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 0, 255), 4\n",
    "        )\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Get face embedding from frame\n",
    "# ======================\n",
    "def get_embedding_from_frame(frame):\n",
    "    \"\"\"Extract face embedding from frame\"\"\"\n",
    "    faces = app.get(frame)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    return faces[0].embedding  # 512-d vector\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Face Detection Preview\n",
    "# ======================\n",
    "def face_detection_preview(cap):\n",
    "    \"\"\"Show face detection preview with rectangle or 'no face detected' message\"\"\"\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100)\n",
    "        )\n",
    "\n",
    "        # Show instruction\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            \"Position your face in the center\",\n",
    "            (50, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (0, 255, 255),\n",
    "            2,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            \"Press S to continue | Q to quit\",\n",
    "            (50, 90),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            # Face detected - draw black rectangle\n",
    "            (x, y, w, h) = faces[0]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 0), 3)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"Face Detected!\",\n",
    "                (50, 130),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "            )\n",
    "        else:\n",
    "            # No face detected\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"No face detected\",\n",
    "                (50, 130),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"s\"):\n",
    "            return True\n",
    "        elif key == ord(\"q\"):\n",
    "            return False\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Initialize camera\n",
    "# ======================\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Show face detection preview first\n",
    "ok = face_detection_preview(cap)\n",
    "if not ok:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "total_captured = 0\n",
    "\n",
    "for pose in poses:\n",
    "\n",
    "    # Show face detection preview for this pose\n",
    "    ok = face_detection_preview(cap)\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    countdown(cap)\n",
    "\n",
    "    saved = 0\n",
    "    \n",
    "    while saved < TOTAL_PER_POSE:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Instruction overlay\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"{pose.upper()} {saved}/{TOTAL_PER_POSE} (Total: {total_captured + saved + 1}/{len(poses) * TOTAL_PER_POSE})\",\n",
    "            (30, 450),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (255, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            # No face detected - show message and continue waiting\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"No face detected! Move to correct position.\",\n",
    "                (50, 200),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "            )\n",
    "            cv2.imshow(\"Capture\", frame)\n",
    "            if cv2.waitKey(400) & 0xFF == ord(\"q\"):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                exit()\n",
    "            continue\n",
    "\n",
    "        # If face detected, draw black outline rectangle\n",
    "        (x, y, w, h) = faces[0]  # take first detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 0), 3)\n",
    "\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "        # Extract embedding from frame\n",
    "        embedding = get_embedding_from_frame(frame)\n",
    "        if embedding is None:\n",
    "            print(f\"Failed to extract embedding for {pose.upper()}\")\n",
    "            continue\n",
    "\n",
    "        # Store embedding\n",
    "        all_embeddings.append(embedding)\n",
    "        saved += 1\n",
    "        total_captured += 1\n",
    "        print(f\"Captured {pose.upper()} embedding {saved}/{TOTAL_PER_POSE}\")\n",
    "\n",
    "        # small delay between captures\n",
    "        if cv2.waitKey(400) & 0xFF == ord(\"q\"):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "\n",
    "print(\"✅ Face embedding capture completed!\")\n",
    "\n",
    "# Average all embeddings from all poses into a single embedding\n",
    "if len(all_embeddings) > 0:\n",
    "    combined_embedding = np.mean(all_embeddings, axis=0)\n",
    "    combined_embedding /= np.linalg.norm(combined_embedding)  # normalize\n",
    "    np.save(OUTPUT_FILE, combined_embedding)\n",
    "    print(f\"✅ Combined embedding saved to {OUTPUT_FILE}\")\n",
    "    print(f\"   Total embeddings captured: {len(all_embeddings)}\")\n",
    "    print(f\"   Embedding shape: {combined_embedding.shape}\")\n",
    "\n",
    "# ======================\n",
    "# Finish screen\n",
    "# ======================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        \"Capture Successful!\",\n",
    "        (150, 200),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.2,\n",
    "        (0, 255, 0),\n",
    "        3,\n",
    "    )\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        \"Press Q to Quit\",\n",
    "        (180, 260),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95cced36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00340365, -0.01121106,  0.01984171, -0.02328454,  0.00929982,\n",
       "        0.08641303,  0.07128216,  0.00627419,  0.01166763,  0.04897914,\n",
       "        0.05759859, -0.01680785, -0.0196371 ,  0.01670406,  0.03560349,\n",
       "       -0.02941946,  0.05668332,  0.01748371,  0.07780635,  0.05108226,\n",
       "        0.09288155, -0.07323273,  0.01998658, -0.06879342,  0.00289742,\n",
       "       -0.04825173, -0.05305039, -0.05051847,  0.04078783, -0.02272603,\n",
       "       -0.05094613, -0.03581465,  0.04685441, -0.01914132,  0.0144848 ,\n",
       "       -0.02831838, -0.04956057,  0.02584866,  0.00907941, -0.03994212,\n",
       "       -0.05864436,  0.01206964, -0.00352414,  0.00500929,  0.03488876,\n",
       "       -0.04004527,  0.02467619, -0.02072682, -0.10129276, -0.01152482,\n",
       "       -0.00796311,  0.03564569, -0.00997269, -0.05422456,  0.02344665,\n",
       "       -0.04600961,  0.03168477, -0.02894596, -0.07201705, -0.05263985,\n",
       "        0.00638105, -0.04468837, -0.05414935,  0.04514595, -0.06599743,\n",
       "        0.01392351, -0.08108491,  0.03002172,  0.03818974,  0.03805869,\n",
       "       -0.01863234, -0.01617581,  0.01168794,  0.01756411,  0.02592603,\n",
       "        0.01446538,  0.02908997, -0.04852666,  0.04524175, -0.02996096,\n",
       "        0.05197652, -0.0817703 , -0.0274574 , -0.02734691, -0.01081226,\n",
       "       -0.03390714, -0.03034569,  0.02282666, -0.07943506,  0.02696469,\n",
       "       -0.04276321,  0.05549996, -0.03931963,  0.00343533,  0.01537998,\n",
       "        0.09669248,  0.02033442,  0.03076182,  0.03294345, -0.04592222,\n",
       "        0.0352754 , -0.04730362,  0.05632291,  0.02805298,  0.02512353,\n",
       "       -0.04295493,  0.02854364, -0.05916343,  0.03844449,  0.03360147,\n",
       "        0.06138054, -0.08433577, -0.01548385, -0.09558292,  0.00140357,\n",
       "        0.00582788, -0.04005431,  0.06310415,  0.07813017, -0.06268665,\n",
       "       -0.02223017,  0.07564965,  0.08998803,  0.00420504, -0.03040872,\n",
       "       -0.07624751, -0.0702684 , -0.02118216,  0.01865835,  0.03405324,\n",
       "       -0.04500397,  0.03147082, -0.10452753, -0.04971664, -0.03818346,\n",
       "        0.03615421,  0.02683061,  0.03283961, -0.08321895, -0.06893483,\n",
       "       -0.04178174,  0.00954789, -0.09770989,  0.03282512, -0.00386318,\n",
       "       -0.00344783,  0.01098823,  0.00163671, -0.00948548,  0.000479  ,\n",
       "       -0.01650899, -0.00714392,  0.00585389,  0.03797202, -0.121355  ,\n",
       "       -0.03140487, -0.03693849,  0.02823737, -0.05147894, -0.02184956,\n",
       "        0.03779281,  0.01513481,  0.00914435,  0.01296509,  0.02569389,\n",
       "        0.02967783,  0.0398738 ,  0.00160317,  0.02959256,  0.06332642,\n",
       "       -0.01804814,  0.06429084,  0.02324833,  0.03333963,  0.02470695,\n",
       "       -0.01971862,  0.02289293, -0.01150065,  0.06565763, -0.04168087,\n",
       "        0.01150645, -0.02152843,  0.0444358 , -0.07400334, -0.0109185 ,\n",
       "       -0.0458552 ,  0.02866312, -0.00993989, -0.0098745 ,  0.00081001,\n",
       "       -0.03195234,  0.08118583,  0.02852924,  0.07491358, -0.01937435,\n",
       "       -0.00775429,  0.02168248, -0.02775363,  0.0069473 , -0.07695743,\n",
       "       -0.03020774, -0.02877122,  0.02891418,  0.02219352,  0.05592847,\n",
       "       -0.01318941,  0.04700062, -0.07293724,  0.05615247, -0.09940985,\n",
       "        0.04463471, -0.01680131,  0.07872018,  0.06858274, -0.04217805,\n",
       "        0.01581705,  0.05792042, -0.07601975,  0.06482758, -0.00379679,\n",
       "        0.00454798, -0.05819359, -0.0045996 , -0.00228483,  0.04240049,\n",
       "       -0.06942277, -0.02813589, -0.0229456 , -0.02267515,  0.00972835,\n",
       "        0.02065441,  0.03726415,  0.07670688,  0.06938511, -0.05023831,\n",
       "       -0.05273761,  0.04975792, -0.00363426, -0.06506116,  0.00157022,\n",
       "       -0.01048753, -0.03748184, -0.06314795,  0.05046205, -0.03901063,\n",
       "       -0.02230355,  0.0702532 , -0.00238566,  0.01654612, -0.03414826,\n",
       "        0.10172109, -0.07549176,  0.02917726, -0.0657857 , -0.03222627,\n",
       "       -0.08190313, -0.03349468, -0.03681519,  0.05403362, -0.00287405,\n",
       "       -0.00735506, -0.06457546,  0.06899251, -0.01736578, -0.0515764 ,\n",
       "       -0.05517186, -0.00476148, -0.08064009, -0.0384395 , -0.01472428,\n",
       "       -0.01273965, -0.06427361, -0.04263619, -0.00388092,  0.06881391,\n",
       "       -0.04782839, -0.04108123,  0.04711599, -0.00416771, -0.00136383,\n",
       "       -0.003475  , -0.03791953, -0.06851125,  0.03210954,  0.04428762,\n",
       "       -0.0429194 , -0.02433056, -0.02917901,  0.0288775 , -0.05075862,\n",
       "       -0.01757371, -0.07709784, -0.03907091, -0.04121737, -0.00549587,\n",
       "       -0.00732447,  0.00985992, -0.0345981 , -0.01761615,  0.01712802,\n",
       "       -0.10054088, -0.01275212, -0.05054415, -0.00012522,  0.04735931,\n",
       "       -0.11433554,  0.06390458, -0.00280447,  0.02107861,  0.02475281,\n",
       "        0.05689212,  0.04931372,  0.06495662, -0.03709   , -0.0464362 ,\n",
       "        0.00602182,  0.01674112,  0.05092664,  0.05232166,  0.00525761,\n",
       "       -0.00149221, -0.07343248,  0.0390101 ,  0.0379388 , -0.01924821,\n",
       "        0.02317951, -0.00430879, -0.06193151, -0.05261004, -0.04517005,\n",
       "        0.00941632, -0.07068009, -0.01018893, -0.06001978, -0.04674305,\n",
       "       -0.03378733, -0.05543341, -0.04446078,  0.00249107, -0.00015761,\n",
       "       -0.01756145,  0.02999485,  0.03355524, -0.02525263, -0.02561594,\n",
       "        0.00078334, -0.00470025, -0.02730184, -0.04581122,  0.04920537,\n",
       "        0.00530205,  0.0073518 ,  0.04748103, -0.04769104,  0.02610873,\n",
       "        0.02891596,  0.05301843, -0.04736421,  0.06383637,  0.00730364,\n",
       "        0.05519553, -0.00768871, -0.04605653, -0.1186806 , -0.01288666,\n",
       "        0.06634627, -0.04451185, -0.05277671, -0.02686699, -0.01560012,\n",
       "        0.04065388,  0.02127794, -0.01387578,  0.00191243, -0.01816366,\n",
       "       -0.02520171, -0.0665743 , -0.01812361,  0.05080719,  0.07530369,\n",
       "       -0.04456118, -0.04034548, -0.02040096, -0.09066064, -0.05245461,\n",
       "       -0.0609603 ,  0.04808012,  0.02197296,  0.01686059, -0.02083438,\n",
       "        0.02616594,  0.02203179, -0.00103659,  0.07323125, -0.07033678,\n",
       "        0.02983533,  0.0072532 ,  0.00281226,  0.04605459,  0.02485687,\n",
       "        0.02112458,  0.01596997, -0.05169224,  0.0109518 , -0.03159149,\n",
       "       -0.01319086,  0.00263239,  0.05145165, -0.09191719,  0.04675505,\n",
       "       -0.01852638,  0.00552087, -0.02341028, -0.0020625 , -0.00695507,\n",
       "       -0.01733766,  0.01762704,  0.10660691, -0.06929988, -0.04282582,\n",
       "       -0.0495779 ,  0.00506633, -0.02569129,  0.08970271, -0.02607846,\n",
       "       -0.01002972,  0.01912977, -0.01437476,  0.00279949,  0.00044595,\n",
       "        0.06885972,  0.06023754,  0.03056248,  0.03352085, -0.07079054,\n",
       "        0.0443467 , -0.03219266,  0.03041672, -0.04192782, -0.05066273,\n",
       "       -0.07938783,  0.00183878,  0.04160482,  0.02573658, -0.04493149,\n",
       "        0.0080934 ,  0.02351288, -0.10308807,  0.00316217,  0.01743309,\n",
       "        0.03041074, -0.03582875, -0.06730664,  0.01701151,  0.08320319,\n",
       "       -0.07607215,  0.02691956, -0.0772013 , -0.01712853, -0.02046227,\n",
       "        0.01034797,  0.00650937, -0.00077361,  0.00844106, -0.06148992,\n",
       "       -0.04277307, -0.03440356,  0.04589471,  0.06597338,  0.03447468,\n",
       "       -0.04817696,  0.02425826, -0.00299934, -0.00401674,  0.08587809,\n",
       "       -0.01626313,  0.07250896, -0.00795451,  0.01612029,  0.01144529,\n",
       "       -0.04240949, -0.03963729,  0.02260266,  0.03122723,  0.05675538,\n",
       "       -0.0361835 , -0.03068428,  0.11609663, -0.00733989, -0.03288278,\n",
       "        0.00384776, -0.0047614 , -0.02305779, -0.01989444, -0.00206772,\n",
       "        0.01892392,  0.05787547, -0.00342444, -0.03799718, -0.03645112,\n",
       "        0.05644707,  0.1002153 ,  0.02612039, -0.04177487,  0.0017367 ,\n",
       "       -0.00641944,  0.04273297, -0.03067657, -0.02909322, -0.00685103,\n",
       "       -0.01956253,  0.02449379], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = np.load(\"embeddings/user2_embedding.npy\")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99ce10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "QFontDatabase: Cannot find font directory /home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/nimesh/anaconda3/envs/nimesh/lib/python3.9/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17886/2225673780.py\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpose\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detection_preview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17886/2225673780.py\u001b[0m in \u001b[0;36mface_detection_preview\u001b[0;34m(cap)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Show preview until user presses S\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ======================\n",
    "# Configuration\n",
    "# ======================\n",
    "USER_NAME = \"user1\"  # change per user\n",
    "SAVE_DIR = \"embeddings\"\n",
    "OUTPUT_FILE = os.path.join(SAVE_DIR, f\"{USER_NAME}_embedding.npy\")\n",
    "TOTAL_PER_POSE = 5\n",
    "poses = [\"front\", \"left\", \"right\"]\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize InsightFace (RetinaFace + ArcFace)\n",
    "app = FaceAnalysis(name=\"buffalo_l\")  # detection + recognition\n",
    "app.prepare(ctx_id=-1)  # CPU; use 0 for GPU\n",
    "\n",
    "# Store all embeddings (across all poses)\n",
    "all_embeddings = []\n",
    "\n",
    "# ======================\n",
    "# Countdown function\n",
    "# ======================\n",
    "def countdown(cap):\n",
    "    for i in range(3, 0, -1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        cv2.putText(frame, str(i), (260, 250), cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 0, 255), 4)\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Get face embedding from frame\n",
    "# ======================\n",
    "def get_embedding_from_frame(frame):\n",
    "    \"\"\"Extract face embedding from frame using RetinaFace\"\"\"\n",
    "    faces = app.get(frame)\n",
    "    if len(faces) == 0:\n",
    "        return None, None\n",
    "    face = faces[0]\n",
    "    return face.embedding, face.bbox  # 512-d vector, bounding box\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Face Detection Preview\n",
    "# ======================\n",
    "def face_detection_preview(cap):\n",
    "    \"\"\"Show preview until user presses S\"\"\"\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        faces = app.get(frame)\n",
    "        if len(faces) > 0:\n",
    "            x1, y1, x2, y2 = map(int, faces[0].bbox)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "            cv2.putText(frame, \"Face Detected!\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(frame, \"Position your face in the center\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press S to continue | Q to quit\", (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"s\"):\n",
    "            return True\n",
    "        elif key == ord(\"q\"):\n",
    "            return False\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Initialize camera\n",
    "# ======================\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Show preview\n",
    "ok = face_detection_preview(cap)\n",
    "if not ok:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "total_captured = 0\n",
    "\n",
    "for pose in poses:\n",
    "    ok = face_detection_preview(cap)\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    countdown(cap)\n",
    "\n",
    "    saved = 0\n",
    "    while saved < TOTAL_PER_POSE:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        embedding, bbox = get_embedding_from_frame(frame)\n",
    "        if embedding is None:\n",
    "            cv2.putText(frame, \"No face detected! Move to correct position.\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Capture\", frame)\n",
    "            if cv2.waitKey(400) & 0xFF == ord(\"q\"):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                exit()\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "        cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "        # Store embedding\n",
    "        all_embeddings.append(embedding)\n",
    "        saved += 1\n",
    "        total_captured += 1\n",
    "        print(f\"Captured {pose.upper()} embedding {saved}/{TOTAL_PER_POSE}\")\n",
    "\n",
    "        if cv2.waitKey(400) & 0xFF == ord(\"q\"):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "\n",
    "print(\"✅ Face embedding capture completed!\")\n",
    "\n",
    "# Average all embeddings into one vector\n",
    "if len(all_embeddings) > 0:\n",
    "    combined_embedding = np.mean(all_embeddings, axis=0)\n",
    "    combined_embedding /= np.linalg.norm(combined_embedding)\n",
    "    np.save(OUTPUT_FILE, combined_embedding)\n",
    "    print(f\"✅ Combined embedding saved to {OUTPUT_FILE}\")\n",
    "    print(f\"Total embeddings captured: {len(all_embeddings)}\")\n",
    "    print(f\"Embedding shape: {combined_embedding.shape}\")\n",
    "\n",
    "# Finish screen\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    cv2.putText(frame, \"Capture Successful!\", (150, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "    cv2.putText(frame, \"Press Q to Quit\", (180, 260), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10e647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Real-time face recognition started. Press Q to quit.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# ==========================\n",
    "# Config\n",
    "# ==========================\n",
    "EMBEDDINGS_DIR = \"embeddings\"\n",
    "THRESHOLD = 0.5  # cosine distance threshold for recognition\n",
    "\n",
    "# Load saved embeddings\n",
    "user_embeddings = {}\n",
    "for file in os.listdir(EMBEDDINGS_DIR):\n",
    "    if file.endswith(\".npy\"):\n",
    "        name = file.split(\"_\")[0]  # e.g., \"user1_embedding.npy\"\n",
    "        emb = np.load(os.path.join(EMBEDDINGS_DIR, file))\n",
    "        user_embeddings[name] = emb\n",
    "\n",
    "# Load ArcFace with RetinaFace for detection\n",
    "app = FaceAnalysis(name=\"buffalo_l\")  # detection + recognition\n",
    "app.prepare(ctx_id=-1)  # CPU; use 0 for GPU\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Real-time face recognition started. Press Q to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Detect faces using RetinaFace\n",
    "    faces = app.get(frame)  # returns list of face objects\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = map(int, face.bbox)  # bounding box\n",
    "        embedding = face.embedding / np.linalg.norm(face.embedding)\n",
    "\n",
    "        # Compare with stored embeddings\n",
    "        best_match = \"Unknown\"\n",
    "        best_score = 1.0\n",
    "        for name, stored_emb in user_embeddings.items():\n",
    "            score = cosine(embedding, stored_emb)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_match = name\n",
    "\n",
    "        if best_score > THRESHOLD:\n",
    "            best_match = \"Unknown\"\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{best_match} ({best_score:.2f})\", (x1, y1-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press Q to Quit\", (35,35), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        \n",
    "\n",
    "    # Show main frame\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c37a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/nimesh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "Processing user1\n",
      "No face detected in dataset/user1/front/1.jpg\n",
      "No face detected in dataset/user1/front/2.jpg\n",
      "No face detected in dataset/user1/front/3.jpg\n",
      "No face detected in dataset/user1/front/4.jpg\n",
      "No face detected in dataset/user1/front/5.jpg\n",
      "No valid face images for user1 front\n",
      "No face detected in dataset/user1/left/1.jpg\n",
      "No face detected in dataset/user1/left/2.jpg\n",
      "No face detected in dataset/user1/left/3.jpg\n",
      "No face detected in dataset/user1/left/4.jpg\n",
      "No face detected in dataset/user1/left/5.jpg\n",
      "No valid face images for user1 left\n",
      "No face detected in dataset/user1/right/1.jpg\n",
      "No face detected in dataset/user1/right/2.jpg\n",
      "No face detected in dataset/user1/right/3.jpg\n",
      "No face detected in dataset/user1/right/4.jpg\n",
      "No face detected in dataset/user1/right/5.jpg\n",
      "No valid face images for user1 right\n",
      "Saved embeddings for user1 -> embeddings/user1_embeddings.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================\n",
    "# Config\n",
    "# ======================\n",
    "DATASET_DIR = \"dataset\"\n",
    "OUTPUT_DIR = \"embeddings\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load ArcFace model\n",
    "app = FaceAnalysis(name=\"buffalo_l\")  # MobileFaceNet ArcFace\n",
    "app.prepare(ctx_id=-1)  # CPU: -1, GPU: 0\n",
    "\n",
    "# ======================\n",
    "# Helper to get embedding from image\n",
    "# ======================\n",
    "def get_embedding(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    faces = app.get(img)\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "        return None\n",
    "    return faces[0].embedding  # 512-d vector\n",
    "\n",
    "# ======================\n",
    "# Process dataset\n",
    "# ======================\n",
    "for user_name in os.listdir(DATASET_DIR):\n",
    "    user_path = os.path.join(DATASET_DIR, user_name)\n",
    "    if not os.path.isdir(user_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing {user_name}\")\n",
    "    user_embeddings = {}\n",
    "\n",
    "    for pose in [\"front\", \"left\", \"right\"]:\n",
    "        pose_path = os.path.join(user_path, pose)\n",
    "        if not os.path.isdir(pose_path):\n",
    "            continue\n",
    "\n",
    "        embeddings_list = []\n",
    "        for img_name in os.listdir(pose_path):\n",
    "            img_path = os.path.join(pose_path, img_name)\n",
    "            emb = get_embedding(img_path)\n",
    "            if emb is not None:\n",
    "                embeddings_list.append(emb)\n",
    "\n",
    "        if len(embeddings_list) == 0:\n",
    "            print(f\"No valid face images for {user_name} {pose}\")\n",
    "            continue\n",
    "\n",
    "        # Average embeddings for this pose\n",
    "        avg_embedding = np.mean(embeddings_list, axis=0)\n",
    "        avg_embedding /= np.linalg.norm(avg_embedding)  # normalize\n",
    "\n",
    "        user_embeddings[pose] = avg_embedding\n",
    "\n",
    "    # Save embeddings for this user\n",
    "    out_file = os.path.join(OUTPUT_DIR, f\"{user_name}_embeddings.npz\")\n",
    "    np.savez(out_file, **user_embeddings)\n",
    "    print(f\"Saved embeddings for {user_name} -> {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274b0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556404c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f20c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
